{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3219a34",
   "metadata": {},
   "source": [
    "# Classification Task for single target compounds + Explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c80bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchdrug import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89bbae",
   "metadata": {},
   "source": [
    "Furthermore, I would suggest building another binary classifier using dual-target compounds as positive and balanced set of single-target 1 and 2 compounds (equally-size subsets) as negative training instances. CNN model accuracy may (or may not) be limited by relative sparseness of dual-target compounds but, if successful, this classifier would provide another attractive basis for model explanation and also facilitate immediate comparison with some of our studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea17e8",
   "metadata": {},
   "source": [
    "## Reprodicubility Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea338a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8645f8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0085e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nonstereo_aromatic_smiles</th>\n",
       "      <th>target_pair</th>\n",
       "      <th>label</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4C)CC3)ccc2n1C</td>\n",
       "      <td>P27338_P22303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#CCN(CCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1</td>\n",
       "      <td>P27338_P22303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3ccc(F)c(F)c3)...</td>\n",
       "      <td>P27338_P22303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3cccc(Cl)c3)CC...</td>\n",
       "      <td>P27338_P22303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3cccc(F)c3)CC2...</td>\n",
       "      <td>P27338_P22303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           nonstereo_aromatic_smiles    target_pair  label  \\\n",
       "0  C#CCN(C)Cc1cc2cc(OCCCC3CCN(Cc4ccccc4C)CC3)ccc2n1C  P27338_P22303      0   \n",
       "1             C#CCN(CCCN1C(=O)c2ccccc2C1=O)Cc1ccccc1  P27338_P22303      0   \n",
       "2  CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3ccc(F)c(F)c3)...  P27338_P22303      0   \n",
       "3  CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3cccc(Cl)c3)CC...  P27338_P22303      0   \n",
       "4  CC(C)(C)c1cc(C=CC(=O)NCCC2CCN(Cc3cccc(F)c3)CC2...  P27338_P22303      0   \n",
       "\n",
       "   target1  target2  \n",
       "0        1        1  \n",
       "1        1        1  \n",
       "2        1        1  \n",
       "3        1        1  \n",
       "4        1        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    70\n",
      "1    70\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATASET_TYPE = \"single\" #\"single\"\n",
    "DATASET_NAME = \"chembl29_dt_cpds_P27338_P22303_balanced\"\n",
    "CSV_DATA_PATH = \"../data/\"+ DATASET_NAME + \".csv\"\n",
    "\n",
    "smiles_df = pd.read_csv(CSV_DATA_PATH, sep = \",\")\n",
    "display(smiles_df.head())\n",
    "print(smiles_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be1baf",
   "metadata": {},
   "source": [
    "## Define Custom Class\n",
    "We need to define the ChEMBL datasets class in order to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8037c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchdrug.core import Registry as R\n",
    "from torchdrug.utils import doc\n",
    "\n",
    "\n",
    "@R.register(\"datasets.ChEMBL\") #only first time you launch the class\n",
    "#@doc.copy_args(data.MoleculeDataset.load_csv, ignore=(\"path\", \"smiles_field\", \"target_fields\"))\n",
    "class ChEMBL(data.MoleculeDataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, path, smiles_field, target_fields, verbose=1, **kwargs):\n",
    "        # path = os.path.expanduser(path)# if not os.path.exists(path):\n",
    "        #     os.makedirs(path)\n",
    "        self.path = path\n",
    "        self.smiles_field = smiles_field\n",
    "        self.target_fields= target_fields\n",
    "        #print(self.path)\n",
    "        # zip_file = utils.download(self.url, path, md5=self.md5)\n",
    "        # csv_file = utils.extract(zip_file)\n",
    "\n",
    "        self.load_csv(self.path, smiles_field=self.smiles_field, target_fields=self.target_fields,\n",
    "                      verbose=verbose, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af8e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ../data/chembl29_dt_cpds_P27338_P22303_balanced.csv: 100%|██████████| 141/141 [00:00<00:00, 47119.50it/s]\n",
      "Constructing molecules from SMILES: 100%|██████████| 140/140 [00:00<00:00, 215.56it/s]\n"
     ]
    }
   ],
   "source": [
    "target_fields = [\"target1\", \"target2\"] if DATASET_TYPE == \"dual\" else [\"label\"]\n",
    "\n",
    "chembl_dataset = ChEMBL(path = CSV_DATA_PATH, smiles_field = \"nonstereo_aromatic_smiles\", target_fields = target_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f0d0d",
   "metadata": {},
   "source": [
    "## Obtain edge index to use with PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec30b4",
   "metadata": {},
   "source": [
    "Visualize molecules using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d61775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e56819c8854655ade0982ffe9e3fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'C'), (2, 'C'), (3, 'N'), (4, 'C'), (5, 'C'), (6, 'C'), (7, 'C'), (8, 'C'), (9, 'C'), (10, 'C'), (11, 'O'), (12, 'C'), (13, 'C'), (14, 'C'), (15, 'C'), (16, 'C'), (17, 'C'), (18, 'N'), (19, 'C'), (20, 'C'), (21, 'C'), (22, 'C'), (23, 'C'), (24, 'C'), (25, 'C'), (26, 'C'), (27, 'C'), (28, 'C'), (29, 'C'), (30, 'C'), (31, 'C'), (32, 'N'), (33, 'C')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pysmiles import read_smiles\n",
    "import networkx as nx\n",
    "    \n",
    "smiles = chembl_dataset.smiles_list\n",
    "mols = []\n",
    "for i in tqdm(range(len(chembl_dataset.smiles_list))):\n",
    "    mols.append(read_smiles(chembl_dataset.smiles_list[i]))\n",
    "\n",
    "mol = mols[0]\n",
    "print(mol.nodes(data='element'))\n",
    "labels = nx.get_node_attributes(mol, 'element') \n",
    "nx.draw(mol, labels = labels, pos=nx.spring_layout(mol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00191aa4",
   "metadata": {},
   "source": [
    "Define edge index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbed2e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343d7c89ea664fd68e0cd5916abb4639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_index_list = []\n",
    "\n",
    "for mol in tqdm(mols):\n",
    "    adj = nx.to_scipy_sparse_matrix(mol).tocoo()\n",
    "    row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "    col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "    edge_index_list.append(edge_index)\n",
    "\n",
    "display(len(mols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b463d4d",
   "metadata": {},
   "source": [
    "Define torchdrug dataset in order to get node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77373077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66e9083c9ac461b8419ab4a279570df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mols_torchdrug_format = []\n",
    "for i in tqdm(range(len(chembl_dataset.smiles_list))):\n",
    "    mols_torchdrug_format.append(data.Molecule.from_smiles(chembl_dataset.smiles_list[i], with_hydrogen = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6065bab",
   "metadata": {},
   "source": [
    "## Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b82094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4af6d7a1c084df79cc011b54d7b860f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_list = []\n",
    "y = torch.LongTensor(chembl_dataset.targets[\"label\"]).to(device)\n",
    "\n",
    "for i in tqdm(range(len(mols))):\n",
    "    data_list.append(Data(x = mols_torchdrug_format[i].node_feature, edge_index = edge_index_list[i], y = y[i], smiles = chembl_dataset.smiles_list[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990e2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChEMBLDatasetPyG(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, data_list = None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        #self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        self.data_list = data_list\n",
    "\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = self.data_list\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3e24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChEMBLDatasetPyG(\".\", data_list = data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0326dbb",
   "metadata": {},
   "source": [
    "Split data in train/val/test (0.8/0.1/0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18cecd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112, 14, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(112, 14, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [int(0.8 * len(chembl_dataset)), int(0.1 * len(chembl_dataset))]\n",
    "lengths += [len(chembl_dataset) - sum(lengths)]\n",
    "\n",
    "print(lengths)\n",
    "dataset = dataset.shuffle()\n",
    "train_data = dataset[:lengths[0]]\n",
    "val_data = dataset[lengths[0]+1:lengths[0] + lengths[1]+1]\n",
    "test_data = dataset[lengths[0] + lengths[1] : ]\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76c5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d1be1",
   "metadata": {},
   "source": [
    "## GCN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf911efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(69, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (conv3): GCNConv(256, 256)\n",
      "  (conv4): GCNConv(256, 256)\n",
      "  (lin): Linear(256, 2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, Linear\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(chembl_dataset.node_feature_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=256).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbe110",
   "metadata": {},
   "source": [
    "## GIN Definition (to fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=69)\n",
      "  (conv2): GINConv(nn=256)\n",
      "  (conv3): GINConv(nn=256)\n",
      "  (conv4): GINConv(nn=256)\n",
      "  (lin): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GINConv(chembl_dataset.node_feature_dim, hidden_channels)\n",
    "        self.conv2 = GINConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GINConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GINConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GIN(hidden_channels=256).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daeff24",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74d91543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Acc: 0.5179, Val Acc: 0.4286\n",
      "Epoch: 001, Train Acc: 0.5268, Val Acc: 0.4286\n",
      "Epoch: 002, Train Acc: 0.6071, Val Acc: 0.5000\n",
      "Epoch: 003, Train Acc: 0.6071, Val Acc: 0.4286\n",
      "Epoch: 004, Train Acc: 0.7143, Val Acc: 0.7143\n",
      "Epoch: 005, Train Acc: 0.7500, Val Acc: 0.7143\n",
      "Epoch: 006, Train Acc: 0.7232, Val Acc: 0.6429\n",
      "Epoch: 007, Train Acc: 0.7589, Val Acc: 0.7143\n",
      "Epoch: 008, Train Acc: 0.7679, Val Acc: 0.7143\n",
      "Epoch: 009, Train Acc: 0.7589, Val Acc: 0.7143\n",
      "Epoch: 010, Train Acc: 0.7679, Val Acc: 0.7143\n",
      "Epoch: 011, Train Acc: 0.7589, Val Acc: 0.7143\n",
      "Epoch: 012, Train Acc: 0.7589, Val Acc: 0.6429\n",
      "Epoch: 013, Train Acc: 0.7768, Val Acc: 0.7857\n",
      "Epoch: 014, Train Acc: 0.7589, Val Acc: 0.6429\n",
      "Epoch: 015, Train Acc: 0.8125, Val Acc: 0.7143\n",
      "Epoch: 016, Train Acc: 0.7857, Val Acc: 0.7143\n",
      "Epoch: 017, Train Acc: 0.7946, Val Acc: 0.7143\n",
      "Epoch: 018, Train Acc: 0.7857, Val Acc: 0.7143\n",
      "Epoch: 019, Train Acc: 0.8214, Val Acc: 0.7143\n",
      "Epoch: 020, Train Acc: 0.8125, Val Acc: 0.7143\n",
      "Epoch: 021, Train Acc: 0.8214, Val Acc: 0.7143\n",
      "Epoch: 022, Train Acc: 0.8214, Val Acc: 0.7857\n",
      "Epoch: 023, Train Acc: 0.8482, Val Acc: 0.7143\n",
      "Epoch: 024, Train Acc: 0.8304, Val Acc: 0.7857\n",
      "Epoch: 025, Train Acc: 0.8482, Val Acc: 0.7857\n",
      "Epoch: 026, Train Acc: 0.8571, Val Acc: 0.7143\n",
      "Epoch: 027, Train Acc: 0.8482, Val Acc: 0.7857\n",
      "Epoch: 028, Train Acc: 0.8661, Val Acc: 0.7857\n",
      "Epoch: 029, Train Acc: 0.8661, Val Acc: 0.7857\n",
      "Epoch: 030, Train Acc: 0.8929, Val Acc: 0.7857\n",
      "Epoch: 031, Train Acc: 0.8839, Val Acc: 0.7857\n",
      "Epoch: 032, Train Acc: 0.9018, Val Acc: 0.7857\n",
      "Epoch: 033, Train Acc: 0.9196, Val Acc: 0.7857\n",
      "Epoch: 034, Train Acc: 0.8929, Val Acc: 0.8571\n",
      "Epoch: 035, Train Acc: 0.8571, Val Acc: 0.9286\n",
      "Epoch: 036, Train Acc: 0.9107, Val Acc: 0.8571\n",
      "Epoch: 037, Train Acc: 0.9554, Val Acc: 0.6429\n",
      "Epoch: 038, Train Acc: 0.9643, Val Acc: 0.7857\n",
      "Epoch: 039, Train Acc: 0.9196, Val Acc: 0.8571\n",
      "Epoch: 040, Train Acc: 0.8214, Val Acc: 0.7143\n",
      "Epoch: 041, Train Acc: 0.9554, Val Acc: 0.8571\n",
      "Epoch: 042, Train Acc: 0.9464, Val Acc: 0.6429\n",
      "Epoch: 043, Train Acc: 0.9018, Val Acc: 0.9286\n",
      "Epoch: 044, Train Acc: 0.9821, Val Acc: 0.7857\n",
      "Epoch: 045, Train Acc: 0.9732, Val Acc: 0.8571\n",
      "Epoch: 046, Train Acc: 0.9286, Val Acc: 0.9286\n",
      "Epoch: 047, Train Acc: 0.9821, Val Acc: 0.7857\n",
      "Epoch: 048, Train Acc: 0.9732, Val Acc: 0.8571\n",
      "Epoch: 049, Train Acc: 0.9643, Val Acc: 0.9286\n",
      "Epoch: 050, Train Acc: 0.9018, Val Acc: 0.9286\n",
      "Epoch: 051, Train Acc: 0.9643, Val Acc: 0.7857\n",
      "Epoch: 052, Train Acc: 0.9821, Val Acc: 0.9286\n",
      "Epoch: 053, Train Acc: 0.9643, Val Acc: 0.9286\n",
      "Epoch: 054, Train Acc: 0.9911, Val Acc: 0.8571\n",
      "Epoch: 055, Train Acc: 0.9643, Val Acc: 0.9286\n",
      "Epoch: 056, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 057, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 058, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 059, Train Acc: 1.0000, Val Acc: 0.7857\n",
      "Epoch: 060, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 061, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 062, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 063, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 064, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 065, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 066, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 067, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 068, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 069, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 070, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 071, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 072, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 073, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 074, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 075, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 076, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 077, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 078, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 079, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 080, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 081, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 082, Train Acc: 0.8661, Val Acc: 0.9286\n",
      "Epoch: 083, Train Acc: 0.7232, Val Acc: 0.6429\n",
      "Epoch: 084, Train Acc: 0.9286, Val Acc: 0.7857\n",
      "Epoch: 085, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 086, Train Acc: 0.9911, Val Acc: 0.7857\n",
      "Epoch: 087, Train Acc: 0.9286, Val Acc: 0.9286\n",
      "Epoch: 088, Train Acc: 0.9643, Val Acc: 0.8571\n",
      "Epoch: 089, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 090, Train Acc: 0.9732, Val Acc: 0.9286\n",
      "Epoch: 091, Train Acc: 0.9821, Val Acc: 0.8571\n",
      "Epoch: 092, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 093, Train Acc: 0.9911, Val Acc: 0.9286\n",
      "Epoch: 094, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 095, Train Acc: 1.0000, Val Acc: 0.8571\n",
      "Epoch: 096, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 097, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 098, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 099, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 100, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 101, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 102, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 103, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 104, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 105, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 106, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 107, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 108, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 109, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 110, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 111, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 112, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 113, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 114, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 115, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 116, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 117, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 118, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 119, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 120, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 121, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 122, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 123, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 124, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 125, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 126, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 127, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 128, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 129, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 130, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 131, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 132, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 133, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 134, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 135, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 136, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 137, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 138, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 139, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 140, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 141, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 142, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 143, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 144, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 145, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 146, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 147, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 148, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 149, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 150, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 151, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 152, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 153, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 154, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 155, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 156, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 157, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 158, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 159, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 160, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 161, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 162, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 163, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 164, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 165, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 166, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 167, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 168, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 169, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 170, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 171, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 172, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 173, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 174, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 175, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 176, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 177, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 178, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 179, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 180, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 181, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 182, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 183, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 184, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 185, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 186, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 187, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 188, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 189, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 190, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 191, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 192, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 193, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 194, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 195, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 196, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 197, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 198, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 199, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 200, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 201, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 202, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 203, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 204, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 205, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 206, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 207, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 208, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 209, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 210, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 211, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 212, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 213, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 214, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 215, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 216, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 217, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 218, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 219, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 220, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 221, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 222, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 223, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 224, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 225, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 226, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 227, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 228, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 229, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 230, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 231, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 232, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 233, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 234, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 235, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 236, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 237, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 238, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 239, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 240, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 241, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 242, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 243, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 244, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 245, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 246, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 247, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 248, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 249, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 250, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 251, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 252, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 253, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 254, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 255, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 256, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 257, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 258, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 259, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 260, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 261, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 262, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 263, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 264, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 265, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 266, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 267, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 268, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 269, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 270, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 271, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 272, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 273, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 274, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 275, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 276, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 277, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 278, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 279, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 280, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 281, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 282, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 283, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 284, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 285, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 286, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 287, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 288, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 289, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 290, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 291, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 292, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 293, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 294, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 295, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 296, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 297, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 298, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 299, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 300, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 301, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 302, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 303, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 304, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 305, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 306, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 307, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 308, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 309, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 310, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 311, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 312, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 313, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 314, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 315, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 316, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 317, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 318, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 319, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 320, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 321, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 322, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 323, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 324, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 325, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 326, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 327, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 328, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 329, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 330, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 331, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 332, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 333, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 334, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 335, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 336, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 337, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 338, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 339, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 340, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 341, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 342, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 343, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 344, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 345, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 346, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 347, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 348, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 349, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 350, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 351, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 352, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 353, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 354, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 355, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 356, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 357, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 358, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 359, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 360, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 361, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 362, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 363, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 364, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 365, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 366, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 367, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 368, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 369, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 370, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 371, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 372, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 373, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 374, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 375, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 376, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 377, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 378, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 379, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 380, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 381, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 382, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 383, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 384, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 385, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 386, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 387, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 388, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 389, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 390, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 391, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 392, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 393, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 394, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 395, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 396, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 397, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 398, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 399, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 400, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 401, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 402, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 403, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 404, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 405, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 406, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 407, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 408, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 409, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 410, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 411, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 412, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 413, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 414, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 415, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 416, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 417, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 418, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 419, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 420, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 421, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 422, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 423, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 424, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 425, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 426, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 427, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 428, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 429, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 430, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 431, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 432, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 433, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 434, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 435, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 436, Train Acc: 1.0000, Val Acc: 0.9286\n",
      "Epoch: 437, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 438, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 439, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 440, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 441, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 442, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 443, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 444, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 445, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 446, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 447, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 448, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 449, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 450, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 451, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 452, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 453, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 454, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 455, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 456, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 457, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 458, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 459, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 460, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 461, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 462, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 463, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 464, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 465, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 466, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 467, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 468, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 469, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 470, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 471, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 472, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 473, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 474, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 475, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 476, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 477, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 478, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 479, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 480, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 481, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 482, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 483, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 484, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 485, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 486, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 487, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 488, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 489, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 490, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 491, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 492, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 493, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 494, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 495, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 496, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 497, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 498, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 499, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 500, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 501, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 502, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 503, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 504, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 505, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 506, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 507, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 508, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 509, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 510, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 511, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 512, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 513, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 514, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 515, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 516, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 517, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 518, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 519, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 520, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 521, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 522, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 523, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 524, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 525, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 526, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 527, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 528, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 529, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 530, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 531, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 532, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 533, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 534, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 535, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 536, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 537, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 538, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 539, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 540, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 541, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 542, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 543, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 544, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 545, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 546, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 547, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 548, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 549, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 550, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 551, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 552, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 553, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 554, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 555, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 556, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 557, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 558, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 559, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 560, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 561, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 562, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 563, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 564, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 565, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 566, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 567, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 568, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 569, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 570, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 571, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 572, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 573, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 574, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 575, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 576, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 577, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 578, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 579, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 580, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 581, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 582, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 583, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 584, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 585, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 586, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 587, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 588, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 589, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 590, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 591, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 592, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 593, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 594, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 595, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 596, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 597, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 598, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 599, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 600, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 601, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 602, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 603, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 604, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 605, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 606, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 607, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 608, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 609, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 610, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 611, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 612, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 613, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 614, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 615, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 616, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 617, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 618, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 619, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 620, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 621, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 622, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 623, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 624, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 625, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 626, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 627, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 628, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 629, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 630, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 631, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 632, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 633, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 634, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 635, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 636, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 637, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 638, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 639, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 640, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 641, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 642, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 643, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 644, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 645, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 646, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 647, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 648, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 649, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 650, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 651, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 652, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 653, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 654, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 655, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 656, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 657, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 658, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 659, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 660, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 661, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 662, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 663, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 664, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 665, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 666, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 667, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 668, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 669, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 670, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 671, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 672, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 673, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 674, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 675, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 676, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 677, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 678, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 679, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 680, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 681, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 682, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 683, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 684, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 685, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 686, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 687, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 688, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 689, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 690, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 691, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 692, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 693, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 694, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 695, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 696, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 697, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 698, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 699, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 700, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 701, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 702, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 703, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 704, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 705, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 706, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 707, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 708, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 709, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 710, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 711, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 712, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 713, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 714, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 715, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 716, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 717, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 718, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 719, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 720, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 721, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 722, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 723, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 724, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 725, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 726, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 727, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 728, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 729, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 730, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 731, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 732, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 733, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 734, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 735, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 736, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 737, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 738, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 739, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 740, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 741, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 742, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 743, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 744, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 745, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 746, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 747, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 748, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 749, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 750, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 751, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 752, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 753, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 754, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 755, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 756, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 757, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 758, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 759, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 760, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 761, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 762, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 763, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 764, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 765, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 766, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 767, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 768, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 769, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 770, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 771, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 772, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 773, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 774, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 775, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 776, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 777, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 778, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 779, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 780, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 781, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 782, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 783, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 784, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 785, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 786, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 787, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 788, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 789, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 790, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 791, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 792, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 793, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 794, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 795, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 796, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 797, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 798, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 799, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 800, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 801, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 802, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 803, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 804, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 805, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 806, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 807, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 808, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 809, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 810, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 811, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 812, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 813, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 814, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 815, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 816, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 817, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 818, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 819, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 820, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 821, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 822, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 823, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 824, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 825, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 826, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 827, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 828, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 829, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 830, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 831, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 832, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 833, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 834, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 835, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 836, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 837, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 838, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 839, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 840, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 841, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 842, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 843, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 844, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 845, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 846, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 847, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 848, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 849, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 850, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 851, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 852, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 853, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 854, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 855, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 856, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 857, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 858, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 859, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 860, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 861, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 862, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 863, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 864, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 865, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 866, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 867, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 868, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 869, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 870, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 871, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 872, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 873, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 874, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 875, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 876, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 877, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 878, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 879, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 880, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 881, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 882, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 883, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 884, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 885, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 886, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 887, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 888, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 889, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 890, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 891, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 892, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 893, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 894, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 895, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 896, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 897, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 898, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 899, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 900, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 901, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 902, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 903, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 904, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 905, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 906, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 907, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 908, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 909, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 910, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 911, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 912, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 913, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 914, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 915, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 916, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 917, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 918, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 919, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 920, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 921, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 922, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 923, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 924, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 925, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 926, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 927, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 928, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 929, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 930, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 931, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 932, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 933, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 934, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 935, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 936, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 937, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 938, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 939, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 940, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 941, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 942, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 943, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 944, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 945, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 946, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 947, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 948, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 949, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 950, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 951, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 952, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 953, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 954, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 955, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 956, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 957, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 958, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 959, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 960, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 961, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 962, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 963, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 964, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 965, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 966, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 967, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 968, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 969, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 970, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 971, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 972, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 973, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 974, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 975, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 976, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 977, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 978, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 979, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 980, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 981, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 982, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 983, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 984, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 985, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 986, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 987, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 988, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 989, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 990, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 991, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 992, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 993, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 994, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 995, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 996, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 997, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 998, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch: 999, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Test Acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(hidden_channels=256).to(device)\n",
    "\n",
    "lr = lr=1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 1000\n",
    "criterion = torch.nn.CrossEntropyLoss() #Note that this case is equivalent to the combination of LogSoftmax torch.nn.NLLLoss.\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         data = data.to(device)\n",
    "         \n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "test_acc = test(test_loader)    \n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7827355",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2f3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_NAME = \"../models/PyG/\" + DATASET_NAME + \"_model_%s.ckpt\"\n",
    "num_file = 0\n",
    "while os.path.exists(MODEL_NAME % num_file):\n",
    "    num_file += 1\n",
    "\n",
    "MODEL_PATH = MODEL_NAME % num_file\n",
    "\n",
    "#MODEL_PATH = \"../models/PyG/\" + DATASET_NAME + \"_model.ckpt\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1deec3",
   "metadata": {},
   "source": [
    "## GNNExplainer\n",
    "Explain the classification of a test cpd using GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3dbf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from torch_geometric.nn import GNNExplainer\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# test_cpd = test_data[0].to(device)\n",
    "# #model = Net().to(device)\n",
    "\n",
    "# #optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# x, edge_index, edge_weight = test_cpd.x, test_cpd.edge_index, None\n",
    "\n",
    "# explainer = GNNExplainer(model, epochs=epochs, return_type='log_prob')\n",
    "\n",
    "# node_feat_mask, edge_mask = explainer.explain_graph(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f07b8",
   "metadata": {},
   "source": [
    "### Plot Explaination Subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c65028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import figure\n",
    "\n",
    "# figure(figsize=(16, 12), dpi=80)\n",
    "# threshold = 0.75\n",
    "# edge_mask = edge_mask.to(\"cpu\")\n",
    "# ax, G = explainer.visualize_subgraph(edge_index = edge_index, edge_mask = edge_mask, node_idx = -1, y=None, threshold=threshold)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3fcee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "# hard_edge_mask.shape\n",
    "\n",
    "# important_edges_index = torch.nonzero(hard_edge_mask == 1)\n",
    "# print(important_edges_index)\n",
    "\n",
    "# edge_index = edge_index.to(device)\n",
    "# important_edges_index = important_edges_index.to(device)\n",
    "\n",
    "# important_edges = torch.index_select(edge_index, dim = 1, index = important_edges_index.squeeze())\n",
    "# print(important_edges)\n",
    "\n",
    "# edges_color = []\n",
    "# mol = read_smiles(test_cpd.smiles)\n",
    "\n",
    "# for edge in mol.edges:\n",
    "#     found_from = False\n",
    "#     found_to = False\n",
    "#     for i in range(important_edges.shape[1]):\n",
    "#         if edge[0] == important_edges[0][i] and edge[1] == important_edges[1][i]:\n",
    "#             found_from = True\n",
    "#         if edge[1] == important_edges[0][i] and edge[0] == important_edges[1][i]:\n",
    "#             found_to = True\n",
    "#     if found_from and found_to:\n",
    "#         edges_color.append(\"red\")\n",
    "#     elif found_from or found_to:\n",
    "#         edges_color.append(\"orange\")\n",
    "#     else:\n",
    "#         edges_color.append(\"black\")   \n",
    "\n",
    "# figure(figsize=(16, 12), dpi=80)\n",
    "# #mol = nx.DiGraph(mol)\n",
    "# labels = nx.get_node_attributes(mol, 'element') \n",
    "# nx.draw(mol, with_labels = True, edge_color = edges_color, pos=nx.spring_layout(mol))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
